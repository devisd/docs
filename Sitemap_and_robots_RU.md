# Скрипт Генерации Sitemap

Этот скрипт генерирует sitemap для веб-сайта <ваш_сайт>, собирая различные URL-адреса и их даты последнего изменения для лучшей оптимизации поисковых систем (SEO) и целей обхода веба.

## Структура и Обзор

- **Базовый URL**: `https://<ваш_сайт>`

Скрипт начинает с получения данных для главной страницы, извлекая разделы, ссылки в шапке и подвале. Эти элементы формируют основную структуру веб-сайта.

- **URL-адреса Последних Новостей**: Извлекает URL-адреса последних новостей из API и форматирует их.

- **URL-адреса Процедур**: Получает детали процедур и форматирует их URL-адреса соответственно.

- **URL-адреса Формуляров**:
  - Получает детали формуляров и обрабатывает их разделы документов для создания отформатированных URL-адресов.

- **Тематические разделы и статьи**:
  - Извлекает тематические разделы и их статьи.
  - Генерирует URL-адреса для тематических разделов и соответствующих статей.

- **URL-адреса Политики Конфиденциальности и Условий Продажи**:
  - Добавляет URL-адреса для политики конфиденциальности и условий продажи.

Скрипт обрабатывает эти разделы, форматирует их URL-адреса и создает sitemap с их соответствующими датами последнего изменения в формате YYYY-MM-DD.

## Важные Заметки

- В скрипте используется Moment.js для форматирования дат последнего изменения.
- Некоторые разделы, такие как законодательство и URL-адреса, связанные со спонсорством, в данный момент закомментированы и не включены в sitemap.

# Конфигурация Robots.txt

Эта конфигурация `robots.txt` предназначена для веб-сайта <ваш_сайт> и указывает директивы для веб-краулеров и роботов поисковых систем.

## Обзор Правил

- **User Agent**: `*` (Применяется ко всем роботам)
  - `allow`: Указывает разрешенные пути для обхода.
    - `/`: Разрешает обход корневой директории веб-сайта.
  - `disallow`: Запрещает обход определенных путей.
    - `/private/`: Запрещает обход директории `/private/` или её содержимого.

## Объявление Sitemap

- **Sitemap**: `https://<ваш_сайт>/sitemap.xml`
  - Направляет краулеров поисковых систем на местоположение sitemap веб-сайта, помогая индексировать и обнаруживать URL-адреса веб-сайта более эффективно.

Этот файл `robots.txt` гарантирует, что веб-краулеры будут следовать определенным правилам при индексации веб-сайта <ваш_сайт>, разрешая доступ к определенным разделам и ограничивая доступ к другим. Он также предоставляет местоположение sitemap для более удобной навигации и индексации URL-адресов веб-сайта.
